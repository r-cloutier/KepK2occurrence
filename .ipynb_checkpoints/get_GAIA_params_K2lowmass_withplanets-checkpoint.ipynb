{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"xtick.labeltop\" on line 358 in\n",
      "/Users/ryancloutier/.matplotlib/matplotlibrc.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "/Users/ryancloutier/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from imports import *\n",
    "from catalog_object import *\n",
    "import mwdust, estimate_PDF\n",
    "from scipy.interpolate import LinearNDInterpolator as lint\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get pre-GAIA data on K2 low mass stars with planets\n",
    "\n",
    "Read in data from the NASA Exoplanet Archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "# get pre-GAIA data on K2 planet hosts\n",
    "cols = (4,6,8,9,10,11,17,18,19,25,26,27,29,30,31,33,34,35,37,38,39,41,42,43,45,46,47,49,52,53,55,56,58,59)\n",
    "fname = 'K2targets/NASAarchive_confirmed_K2lowmassstars.csv'\n",
    "d = np.genfromtxt(fname, delimiter=',', skip_header=73, usecols=cols)\n",
    "K2campaign,ras,decs,Ps,ehiP,eloP,D,ehiD,eloD,rpRs,ehirpRs,elorpRs,rps,ehirp,elorp,Teff,ehiTeff,eloTeff,logg,ehilogg,elologg,FeH,ehiFeH,eloFeH,Rss,ehiRs,eloRs,Kepmag,Jmag,eJmag,Hmag,eHmag,Kmag,eKmag = d.T\n",
    "EPICnums = np.array([int(s.split(' ')[1]) for s in np.genfromtxt(fname, delimiter=',', skip_header=73, usecols=(1),\n",
    "                                                                 dtype='|S50')])\n",
    "N = EPICnums.size\n",
    "print N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add missing uncertainties\n",
    "g = np.isnan(ehiTeff)\n",
    "ehiTeff[g], eloTeff[g] = 100, 100\n",
    "ehilogg[g], elologg[g] = .1, .1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get GAIA data on K2 low mass stars with planets\n",
    "\n",
    "Cross-match K2 low mass stars with planets to GAIA DR2 and save parallaxes, photometry, and positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get GAIA data from Megan Bedell's Kepler-GAIA catalog\n",
    "hdu = fits.open('K2targets/k2_dr2_4arcsec.fits')[1]\n",
    "\n",
    "hasGAIA = np.zeros(N, dtype=bool)\n",
    "pars, epars = np.zeros(N), np.zeros(N)\n",
    "GBPmags, eGBPmags = np.zeros(N), np.zeros(N)\n",
    "GRPmags, eGRPmags = np.zeros(N), np.zeros(N)\n",
    "ras, decs = np.zeros(N), np.zeros(N)\n",
    "ls, bs = np.zeros(N), np.zeros(N)\n",
    "for i in range(N):\n",
    "    \n",
    "    g = hdu.data['epic_number'] == EPICnums[i]\n",
    "    if g.sum() == 0:   # no match\n",
    "        pars[i], epars[i] = np.repeat(np.nan, 2)\n",
    "        GBPmags[i], eGBPmags[i] = np.repeat(np.nan, 2)\n",
    "        GRPmags[i], eGRPmags[i] = np.repeat(np.nan, 2)\n",
    "        ras[i], decs[i] = np.repeat(np.nan, 2)\n",
    "        ls[i], bs[i] = np.repeat(np.nan, 2)\n",
    "        \n",
    "    elif g.sum() >= 1:  # at least one match (take the first entry if multiple matches)\n",
    "        index = 0\n",
    "        hasGAIA[i] = True\n",
    "        pars[i], epars[i] = hdu.data['parallax'][g][index], hdu.data['parallax_error'][g][index]\n",
    "\n",
    "        GBPmags[i] = hdu.data['phot_bp_mean_mag'][g][index]            \n",
    "        FBP = hdu.data['phot_bp_mean_flux'][g][index]\n",
    "        eFBP = hdu.data['phot_bp_mean_flux_error'][g][index]\n",
    "        eGBPmags[i] = -2.5*np.log10(FBP / (FBP+eFBP))\n",
    "        \n",
    "        GRPmags[i] = hdu.data['phot_rp_mean_mag'][g][index]            \n",
    "        FRP = hdu.data['phot_rp_mean_flux'][g][index]\n",
    "        eFRP = hdu.data['phot_rp_mean_flux_error'][g][index]\n",
    "        eGRPmags[i] = -2.5*np.log10(FRP / (FRP+eFRP))\n",
    "        \n",
    "        ras[i], decs[i] = hdu.data['ra'][g][index], hdu.data['dec'][g][index]\n",
    "        ls[i], bs[i] = hdu.data['l'][g][index], hdu.data['b'][g][index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute distance posteriors (from Bailor-Jones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get distance posteriors from Bailor-Jones R scripts\n",
    "cwd = os.getcwd()\n",
    "os.chdir('GaiaDistances/')\n",
    "prefix = 'EPICID'\n",
    "overwrite = False\n",
    "for i in range(N):\n",
    "       \n",
    "    cmd_prefix = 'Rscript get_dist_post.R %s'%prefix\n",
    "    cmd = '%s_%i %.6e %.6e %.6f %.6f'%(cmd_prefix, EPICnums[i], pars[i], epars[i], ls[i], bs[i])\n",
    "\n",
    "    # if posterior doesn't exist, compute it using the R script\n",
    "    fout = 'DistancePosteriors/%s_%i.csv'%(prefix, EPICnums[i])\n",
    "    if ((not os.path.exists(fout)) or overwrite) and (hasGAIA[i]):\n",
    "        os.system(cmd)\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save distance point estimates\n",
    "Nsamp = 1000\n",
    "dists, ehidists, elodists = np.zeros(N), np.zeros(N), np.zeros(N)\n",
    "mus, ehimus, elomus = np.zeros(N), np.zeros(N), np.zeros(N)\n",
    "for i in range(N):\n",
    "    \n",
    "    if hasGAIA[i]:\n",
    "        # get distance posterior\n",
    "        fname = 'GaiaDistances/DistancePosteriors/%s_%i.csv'%(prefix, EPICnums[i])\n",
    "        distarr, probarr = np.loadtxt(fname, delimiter=',', skiprows=1, usecols=(1,2)).T\n",
    "        samp_dist = np.random.choice(distarr, Nsamp, p=probarr/probarr.sum()) + np.random.randn(Nsamp)*1e-2\n",
    "\n",
    "        # save distance point estimates\n",
    "        v = np.percentile(samp_dist, (16,50,84))\n",
    "        dists[i], ehidists[i], elodists[i] = v[1], v[2]-v[1], v[1]-v[0]\n",
    "    \n",
    "        # sample and save distance modulus\n",
    "        samp_mu = 5*np.log10(samp_dist) - 5\n",
    "        v = np.percentile(samp_mu, (16,50,84))\n",
    "        mus[i], ehimus[i], elomus[i] = v[1], v[2]-v[1], v[1]-v[0]\n",
    "        \n",
    "    else:\n",
    "        dists[i], ehidists[i], elodists[i] = np.repeat(np.nan, 3)\n",
    "        mus[i], ehimus[i], elomus[i] = np.repeat(np.nan, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimate extinction using mwdust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_AK_mwdust(ls, bs, dist, edist, eAK_frac=.3, RV=3.1):\n",
    "    '''Using the EB-V map from 2014MNRAS.443.2907S and the extinction vector\n",
    "    RK = 0.31 from Schlafly and Finkbeiner 2011 (ApJ 737, 103). \n",
    "    Where does RV=3.1 come from? See the MIST BC tables where RV is fixed to 3.1'''\n",
    "    dustmapK = mwdust.Combined15(filter='2MASS Ks')\n",
    "    dustmapV = mwdust.Combined15(filter=None)  # returns E(B-V) rather than A_lambda\n",
    "    dist_kpc, edist_kpc = np.ascontiguousarray(dist)*1e-3, np.ascontiguousarray(edist)*1e-3\n",
    "    ls, bs = np.ascontiguousarray(ls), np.ascontiguousarray(bs)\n",
    "    AK, eAK = np.zeros(ls.size), np.zeros(ls.size)\n",
    "    AV = np.zeros(ls.size)\n",
    "    for i in range(ls.size):\n",
    "        v = dustmapK(ls[i], bs[i],\n",
    "                     np.array([dist_kpc[i], dist_kpc[i]+edist_kpc[i]]))\n",
    "        AK[i], eAK[i] = v[0], np.sqrt(abs(np.diff(v))**2 + (eAK_frac*v[0])**2)\n",
    "        v = dustmapV(ls[i], bs[i],\n",
    "                     np.array([dist_kpc[i], dist_kpc[i]+edist_kpc[i]]))\n",
    "        AV[i] = v[0]*RV\n",
    "    return AK, eAK, AV\n",
    "\n",
    "\n",
    "def MAD(arr):\n",
    "    return np.median(abs(arr - np.median(arr)))\n",
    "    \n",
    "\n",
    "AKs, eAKs, AVs = np.zeros(N), np.zeros(N), np.zeros(N)\n",
    "for i in range(N):\n",
    "    \n",
    "    if hasGAIA[i]:\n",
    "\n",
    "        # get distance posterior\n",
    "        fname = 'GaiaDistances/DistancePosteriors/EPICID_%i.csv'%EPICnums[i]\n",
    "        distarr, probarr = np.loadtxt(fname, delimiter=',', skiprows=1, usecols=(1,2)).T\n",
    "        samp_dist = np.random.choice(distarr, Nsamp, p=probarr/probarr.sum()) + np.random.randn(Nsamp)*1e-2\n",
    "        \n",
    "        # compute K-band extinction\n",
    "        AKs[i], eAKs[i], AVs[i] = _compute_AK_mwdust(ls[i], bs[i], dists[i], MAD(samp_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup functions to compute bolometric corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _interpolate_BCK(Teff, e_Teff, logg, FeH, Av):\n",
    "    '''Interpolate the MIST bolometric correction grids to get a star's K-band bolometric correction.'''\n",
    "    # select a metallicity grid\n",
    "    FeHgrid = np.array([-4,-3.5,-3,-2.75,-2.5,-2.25,-2,-1.75,-1.5,-1.25,-1,-.75,-.5,-.25,0,.25,.5,.75])\n",
    "    inds, coeffs = _get_interpolation_coeffs(FeHgrid, FeH)\n",
    "    if np.any(coeffs == 0):\n",
    "        FeHs = FeHgrid[inds[coeffs>0]]\n",
    "        coeffs = np.ones(1)\n",
    "    else:\n",
    "        FeHs = FeHgrid[inds]\n",
    "    \n",
    "    # interpolate over remaining parameters for all metallicity grids and with sampled Teff\n",
    "    BCKs = np.zeros((FeHs.size, 2))\n",
    "    for i in range(FeHs.size):\n",
    "        \n",
    "        # get BC grid for a fixed Fe/H\n",
    "        label = 'p' if FeHs[i] >= 0 else 'm'\n",
    "        fname = 'UBVRIplus/feh%s%.3d.UBVRIplus'%(label, abs(FeHs[i])*1e2)\n",
    "        Teffgrid, logggrid, Avgrid, BCKgrid  = np.loadtxt(fname, skiprows=5, usecols=(0,1,3,12)).T\n",
    "        \n",
    "        # compute a separate BCK for Teff across its 1 sigma uncertainty to estimate the uncertainty in BCK\n",
    "        # because it is dominated by uncertainies in Teff which have the strongest effect on the stellar SED\n",
    "        BCKs_Teff, j = np.zeros(0), 0\n",
    "        for t in Teff+np.arange(2)*e_Teff:\n",
    "            # interpolate to get BCK\n",
    "            lint_BCK = lint(np.array([Teffgrid,logggrid,Avgrid]).T, BCKgrid)\n",
    "            BCKs[i,j] = np.append(BCKs_Teff, float(lint_BCK(t, logg, Av)) * coeffs[i])\n",
    "            j += 1\n",
    "            \n",
    "    # sum contributions from each Fe/H\n",
    "    BCKs = np.sum(BCKs, axis=0)\n",
    "    assert BCKs.size == 2\n",
    "    BCK, e_BCK = BCKs[0], abs(float(np.diff(BCKs)))\n",
    "    return BCK, e_BCK\n",
    "\n",
    "                     \n",
    "def _get_interpolation_coeffs(arr, val):\n",
    "    if val < arr.min():\n",
    "        return np.argsort(arr)[:1], np.ones(1)\n",
    "    elif val > arr.max():\n",
    "        return np.argsort(arr)[-1:], np.ones(1)\n",
    "    else:\n",
    "        edgeinds = np.argsort(abs(arr-val))[:2]\n",
    "        edgevals = arr[edgeinds]\n",
    "        diff = abs(float(np.diff(edgevals)))\n",
    "        c1 = abs(val-edgevals[0]) / diff\n",
    "        coeffs = np.array([1-c1, c1]).reshape(2)\n",
    "        return edgeinds, coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute new stellar parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sample_Rs_from_MK_Mdwarfs(samp_MK):\n",
    "    '''Use relation from Mann+2015 (table 1) for M dwarfs'''\n",
    "    if (np.median(samp_MK) > 4.6) & (np.median(samp_MK) < 9.8):\n",
    "        a, b, c, Rs_sigma_frac = 1.9515, -.3520, .01680, .0289\n",
    "        p = np.poly1d((c,b,a))\n",
    "        samp_MK_tmp = np.copy(samp_MK)\n",
    "        #samp_MK_tmp[(samp_MK<=4.6) | (samp_MK>=9.8)] = np.nan\n",
    "        samp_Rs = p(samp_MK_tmp)\n",
    "        samp_Rs += np.random.normal(0, samp_Rs*Rs_sigma_frac, samp_MK.size)\n",
    "    else:\n",
    "        samp_Rs = np.zeros_like(samp_MK) + np.nan\n",
    "    return samp_Rs\n",
    "\n",
    "\n",
    "def _sample_Rs_from_MK_Kdwarfs(samp_MK, samp_BCK, samp_Teff):\n",
    "    if (np.median(samp_MK) < 4.6):\n",
    "        samp_Mbol = samp_MK + samp_BCK\n",
    "        samp_L = 3.0128e28 * 10**(-.4*samp_Mbol)  # Watts\n",
    "        sigma = 5.67e-8\n",
    "        samp_Rs = rvs.m2Rsun(np.sqrt(samp_L / (4*np.pi*sigma*samp_Teff**4)))\n",
    "    else:\n",
    "        samp_Rs = np.zeros_like(samp_MK) + np.nan\n",
    "    return samp_Rs\n",
    "        \n",
    "\n",
    "def _sample_Teff_from_colors(samp_GBPmag, samp_GRPmag, samp_Jmag, samp_Hmag,\n",
    "                             Teff_scatter=49):\n",
    "    '''Use the relation from Mann+2015 (table 2)'''\n",
    "    a, b, c, d, e, f, g = 3.172, -2.475, 1.082, -.2231, .01738, .08776, -.04355\n",
    "    pG = np.poly1d((e,d,c,b,a))\n",
    "    p2 = np.poly1d((g,f,0))\n",
    "    samp_Teff = 35e2 * (pG(samp_GBPmag-samp_GRPmag) + p2(samp_Jmag-samp_Hmag)) \\\n",
    "                + np.random.normal(0, Teff_scatter, samp_Jmag.size)\n",
    "    return samp_Teff\n",
    "\n",
    "\n",
    "def _sample_Ms_from_MK_Mdwarfs(samp_MK):\n",
    "    '''Use relation from Benedict+2016'''\n",
    "    if (np.median(samp_MK) >= 5) & (np.median(samp_MK) < 10):\n",
    "        c0 = np.random.normal(.2311, 4e-4, samp_MK.size)\n",
    "        c1 = np.random.normal(-.1352, 7e-4, samp_MK.size)\n",
    "        c2 = np.random.normal(.04, 5e-4, samp_MK.size)\n",
    "        c3 = np.random.normal(.0038, 2e-4, samp_MK.size)\n",
    "        c4 = np.random.normal(-.0032, 1e-4, samp_MK.size)\n",
    "        samp_MK_tmp = np.copy(samp_MK)\n",
    "        #samp_MK_tmp[(samp_MK<=4.6) | (samp_MK>10)] = np.nan\n",
    "        #samp_MK_tmp[samp_MK>=10] = np.nan\n",
    "        dMK = samp_MK_tmp - 7.5\n",
    "        samp_Ms = c0 + c1*dMK + c2*dMK**2 + c3*dMK**3 + c4*dMK**4\n",
    "    else:\n",
    "        samp_Ms = np.zeros_like(samp_MK) + np.nan\n",
    "    return samp_Ms\n",
    "\n",
    "\n",
    "def _sample_Ms_from_MK_Kdwarfs(samp_MK):\n",
    "    '''Empirical relation with stellar mass from Mann+2018 (Table 6)'''\n",
    "    if (np.median(samp_MK) >= 4) & (np.median(samp_MK) < 11):\n",
    "        zp = 7.5\n",
    "        ais = np.array([-.642, -.208, -8.43e-4, 7.87e-3, 1.42e-4, -2.13e-4])\n",
    "        samp_Ms = np.array([10**np.sum(ais*(mk - zp)**np.arange(ais.size)) for mk in samp_MK])\n",
    "        sig_Ms = _get_sigMs(np.median(samp_MK))\n",
    "        samp_Ms += np.random.normal(0, sig_Ms, samp_MK.size)\n",
    "    else:\n",
    "        samp_Ms = np.zeros_like(samp_MK) + np.nan\n",
    "    return samp_Ms\n",
    "        \n",
    "\n",
    "def _get_sigMs(MK):\n",
    "    '''Return the characeristic scatter in stellar mass given MK \n",
    "    from the empirial relation in Mann+2018 (Table 7)'''\n",
    "    assert (MK >= 4) & (MK <= 11)\n",
    "    MKarr = np.delete(np.arange(4,11.1,.5), 7)\n",
    "    sig_Mss = np.array([28,16,15,12,9.9,8.1,6.4,3.9,3.2,2.6,2.3,2.2,2.1,2.4]) * 1e-3\n",
    "    assert MKarr.size == sig_Mss.size\n",
    "    s = np.argsort(abs(MKarr - MK))\n",
    "    return sig_Mss[s][0]\n",
    "    \n",
    "    \n",
    "def _compute_logg(Ms, Rs):\n",
    "    G = 6.67e-11\n",
    "    return np.log10(G*rvs.Msun2kg(Ms)*1e2 / rvs.Rsun2m(Rs)**2)\n",
    "\n",
    "\n",
    "def _compute_percentiles(samples):\n",
    "    v = np.percentile(samples, (16,50,84))\n",
    "    return v[1], v[2]-v[1], v[1]-v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize arrays\n",
    "nanarr = np.repeat(np.nan, N)\n",
    "isMdwarf = np.zeros(N, dtype=bool)\n",
    "BCKs, eBCKs = np.copy(nanarr), np.copy(nanarr)\n",
    "MKs, ehiMKs, eloMKs = np.copy(nanarr), np.copy(nanarr), np.copy(nanarr)\n",
    "Rss2, ehiRss2, eloRss2 = np.copy(nanarr), np.copy(nanarr), np.copy(nanarr)\n",
    "Teffs2, ehiTeffs2, eloTeffs2 = np.copy(nanarr), np.copy(nanarr), np.copy(nanarr)\n",
    "Mss2, ehiMss2, eloMss2 = np.copy(nanarr), np.copy(nanarr), np.copy(nanarr)\n",
    "loggs2, ehiloggs2, elologgs2 = np.copy(nanarr), np.copy(nanarr), np.copy(nanarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0\n",
      "1 0.0142857142857\n",
      "2 0.0285714285714\n",
      "3 0.0428571428571\n",
      "4 0.0571428571429\n",
      "5 0.0714285714286\n",
      "6 0.0857142857143\n",
      "7 0.1\n",
      "8 0.114285714286\n",
      "9 0.128571428571\n",
      "10 0.142857142857\n",
      "11 0.157142857143\n",
      "12 0.171428571429\n",
      "13 0.185714285714\n",
      "14 0.2\n",
      "15 0.214285714286\n",
      "16 0.228571428571\n",
      "17 0.242857142857\n",
      "18 0.257142857143\n",
      "19 0.271428571429\n",
      "20 0.285714285714\n",
      "21 0.3\n",
      "22 0.314285714286\n",
      "23 0.328571428571\n",
      "24 0.342857142857\n",
      "25 0.357142857143\n",
      "26 0.371428571429\n",
      "27 0.385714285714\n",
      "28 0.4\n",
      "29 0.414285714286\n",
      "30 0.428571428571\n",
      "31 0.442857142857\n",
      "32 0.457142857143\n",
      "33 0.471428571429\n",
      "34 0.485714285714\n",
      "35 0.5\n",
      "36 0.514285714286\n",
      "37 0.528571428571\n",
      "38 0.542857142857\n",
      "39 0.557142857143\n",
      "40 0.571428571429\n",
      "41 0.585714285714\n",
      "42 0.6\n",
      "43 0.614285714286\n",
      "44 0.628571428571\n",
      "45 0.642857142857\n",
      "46 0.657142857143\n",
      "47 0.671428571429\n",
      "48 0.685714285714\n",
      "49 0.7\n",
      "50 0.714285714286\n",
      "51 0.728571428571\n",
      "52 0.742857142857\n",
      "53 0.757142857143\n",
      "54 0.771428571429\n",
      "55 0.785714285714\n",
      "56 0.8\n",
      "57 0.814285714286\n",
      "58 0.828571428571\n",
      "59 0.842857142857\n",
      "60 0.857142857143\n",
      "61 0.871428571429\n",
      "62 0.885714285714\n",
      "63 0.9\n",
      "64 0.914285714286\n",
      "65 0.928571428571\n",
      "66 0.942857142857\n",
      "67 0.957142857143\n",
      "68 0.971428571429\n",
      "69 0.985714285714\n"
     ]
    }
   ],
   "source": [
    "# compute stellar parameters\n",
    "for i in range(N):\n",
    "    \n",
    "    print i, float(i)/N\n",
    "    \n",
    "    if hasGAIA[i]:\n",
    "        # sample input parameters\n",
    "        samp_Jmag = np.random.randn(Nsamp)*eJmag[i] + Jmag[i]\n",
    "        samp_Hmag = np.random.randn(Nsamp)*eHmag[i] + Hmag[i]\n",
    "        samp_Kmag = np.random.randn(Nsamp)*eKmag[i] + Kmag[i]\n",
    "        samp_GBPmag = np.random.randn(Nsamp)*eGBPmags[i] + GBPmags[i]\n",
    "        samp_GRPmag = np.random.randn(Nsamp)*eGRPmags[i] + GRPmags[i]\n",
    "        samp_AK = np.random.randn(Nsamp)*eAKs[i] + AKs[i]\n",
    "        _,_,samp_mu = estimate_PDF.get_samples_from_percentiles(mus[i], ehimus[i], elomus[i], Nsamp=Nsamp)\n",
    "        _,_,samp_logg = estimate_PDF.get_samples_from_percentiles(logg[i], ehilogg[i], abs(elologg[i]), Nsamp=Nsamp)\n",
    "        _,_,samp_FeH = estimate_PDF.get_samples_from_percentiles(FeH[i], ehiFeH[i], abs(eloFeH[i]), Nsamp=Nsamp)\n",
    "        \n",
    "        # compute new effective temperature\n",
    "        samp_Teff = _sample_Teff_from_colors(samp_GBPmag, samp_GRPmag, samp_Jmag, samp_Hmag)\n",
    "        Teffs2[i], ehiTeffs2[i], eloTeffs2[i] = _compute_percentiles(samp_Teff)\n",
    "        \n",
    "        # compute MK to see if we have an M dwarf\n",
    "        samp_MK = samp_Kmag - samp_mu - samp_AK\n",
    "        MKs[i], ehiMKs[i], eloMKs[i] = _compute_percentiles(samp_MK)\n",
    "        isMdwarf[i] = (MKs[i] > 4.6) & (MKs[i] < 9.8)\n",
    "        \n",
    "        # compute bolometric corrections for non-M dwarfs and update stellar radii\n",
    "        if not isMdwarf[i]:\n",
    "            BCKs[i], eBCKs[i] = _interpolate_BCK(Teffs2[i], ehiTeffs2[i], logg[i], FeH[i], AVs[i])\n",
    "            samp_BCK = np.random.randn(Nsamp)*eBCKs[i] + BCKs[i]\n",
    "            samp_Rs = _sample_Rs_from_MK_Kdwarfs(samp_MK, samp_BCK, samp_Teff)\n",
    "        # M dwarf radii\n",
    "        else:\n",
    "            samp_Rs = _sample_Rs_from_MK_Mdwarfs(samp_MK)\n",
    "\n",
    "        # compute masses from empirical relations depending on MK\n",
    "        if (MKs[i] >= 5):\n",
    "            samp_Ms = _sample_Ms_from_MK_Mdwarfs(samp_MK)  # Benedict+2106\n",
    "        else:\n",
    "            samp_Ms = _sample_Ms_from_MK_Kdwarfs(samp_MK)\n",
    "            \n",
    "        # update stellar parameters\n",
    "        Rss2[i], ehiRss2[i], eloRss2[i] = _compute_percentiles(samp_Rs)\n",
    "        Mss2[i], ehiMss2[i], eloMss2[i] = _compute_percentiles(samp_Ms)\n",
    "        loggs2[i], ehiloggs2[i], elologgs2[i] = _compute_percentiles(_compute_logg(samp_Ms, samp_Rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save parameters to a catalog object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryancloutier/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: RuntimeWarning: invalid value encountered in less_equal\n",
      "  app.launch_new_instance()\n",
      "/Users/ryancloutier/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: RuntimeWarning: invalid value encountered in greater\n",
      "  app.launch_new_instance()\n",
      "/Users/ryancloutier/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: RuntimeWarning: invalid value encountered in less\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# flag stars of interest for occurrence rate calculations\n",
    "iscool = np.zeros(N, dtype=bool)\n",
    "g = (Teffs2 - eloTeffs2 <= 4700) & (loggs2 + ehiloggs2 > 4) & (Rss2 - eloRss2 < .75)\n",
    "iscool[g] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = catalog_object('Results/K2lowmassstars_withplanets_GAIA_v1')\n",
    "self.Nstars = N\n",
    "self.hasGAIA, self.isMdwarf, self.iscool = hasGAIA, isMdwarf, iscool\n",
    "self.N_hasGAIA, self.N_isMdwarf, self.N_iscool = self.hasGAIA.sum(), self.isMdwarf.sum(), self.iscool.sum()\n",
    "\n",
    "# positions\n",
    "self.ras, self.decs = ras, decs\n",
    "self.ls, self.bs = ls, bs\n",
    "\n",
    "# photometry\n",
    "self.GBPmags, self.e_GBPmags = GBPmags, eGBPmags\n",
    "self.GRPmags, self.e_GRPmags = GRPmags, eGRPmags\n",
    "self.Jmags, self.e_Jmags = Jmag, eJmag\n",
    "self.Hmags, self.e_Hmags = Hmag, eHmag\n",
    "self.Kmags, self.e_Kmags = Kmag, eKmag\n",
    "\n",
    "# GAIA distances\n",
    "self.dists, self.ehi_dists, self.elo_dists = dists, ehidists, elodists\n",
    "self.mus, self.ehi_mus, self.elo_mus = mus, ehimus, elomus\n",
    "self.MKs, self.ehi_MKs, self.elo_MKs = MKs, ehiMKs, eloMKs\n",
    "self.AKs, self.e_AKs, self.AVs = AKs, eAKs, AVs\n",
    "\n",
    "# updated stellar parameters\n",
    "self.BCKs, self.e_BCKs = BCKs, eBCKs\n",
    "self.Teffs2, self.ehi_Teffs2, self.elo_Teffs2 = Teffs2, ehiTeffs2, eloTeffs2\n",
    "self.Rss2, self.ehi_Rss2, self.elo_Rss2 = Rss2, ehiRss2, eloRss2\n",
    "self.Mss2, self.ehi_Mss2, self.elo_Mss2 = Mss2, ehiMss2, eloMss2\n",
    "self.loggs2, self.ehi_loggs2, self.elo_loggs2 = loggs2, ehiloggs2, elologgs2\n",
    "\n",
    "# add previous stellar parameters\n",
    "self.Teffs1, self.ehi_Teffs1, self.elo_Teffs1 = Teff, ehiTeff, abs(eloTeff)\n",
    "self.loggs1, self.ehi_loggs1, self.elo_loggs1 = logg, ehilogg, abs(elologg)\n",
    "self.FeH1, self.ehi_FeH1, self.elo_FeH1 = FeH, ehiFeH, abs(eloFeH)\n",
    "self.Rss1, self.ehi_Rss1, self.elo_Rss1 = Rss, ehiRs, abs(eloRs)\n",
    "#self.Mss1, self.ehi_Mss1, self.elo_Mss1 = Mss, ehiMs, abs(eloMs)\n",
    "\n",
    "# planet parameters\n",
    "self.Ps, self.ehi_Ps, self.elo_Ps = Ps, ehiP, abs(eloP)\n",
    "self.rpRs, self.ehi_rpRs, self.elo_rpRs = rpRs, ehirpRs, abs(elorpRs)\n",
    "self.rps1, self.ehi_rps1, self.elo_rps1 = rps, ehirp, abs(elorp)\n",
    "\n",
    "# update planet radii\n",
    "self.rps2, self.ehi_rps2, self.elo_rps2 = np.zeros(N), np.zeros(N), np.zeros(N)\n",
    "for i in range(N):\n",
    "    _,_,samp_rpRs = estimate_PDF.get_samples_from_percentiles(self.rpRs[i], self.ehi_rpRs[i], self.elo_rpRs[i], Nsamp=Nsamp)\n",
    "    _,_,samp_Rs = estimate_PDF.get_samples_from_percentiles(self.Rss2[i], self.ehi_Rss2[i], self.elo_Rss2[i], Nsamp=Nsamp)\n",
    "    samp_rp = rvs.m2Rearth(rvs.Rsun2m(samp_rpRs*samp_Rs))\n",
    "    self.rps2[i], self.ehi_rps2[i], self.elo_rps2[i] = _compute_percentiles(samp_rp)\n",
    "    \n",
    "self._pickleobject()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

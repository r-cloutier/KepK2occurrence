{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n",
    "from catalog_object import *\n",
    "import mwdust, estimate_PDF\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get pre-GAIA data on K2 M dwarfs with planets\n",
    "\n",
    "Read in data from the NASA Exoplanet Archive and cross-match with 2MASS data to get photometric uncertainties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "# get pre-GAIA data on Kepler planet hosts\n",
    "cols = (4,6,8,9,10,11,17,18,19,25,26,27,29,30,31,33,34,35,37,38,39,41,42,43,45,46,47,49,52,53,55,56,58,59)\n",
    "fname = 'K2targets/NASAarchive_confirmed_K2lowmassstars.csv'\n",
    "d = np.genfromtxt(fname, delimiter=',', skip_header=73, usecols=cols)\n",
    "K2campaign,ras,decs,Ps,ehiP,eloP,D,ehiD,eloD,rpRs,ehirpRs,elorpRs,rps,ehirp,elorp,Teff,ehiTeff,eloTeff,logg,ehilogg,elologg,FeH,ehiFeH,eloFeH,Rss,ehiRs,eloRs,Kepmag,Jmag,eJmag,Hmag,eHmag,Kmag,eKmag = d.T\n",
    "EPICnums = np.array([int(s.split(' ')[1]) for s in np.genfromtxt(fname, delimiter=',', skip_header=73, usecols=(1),\n",
    "                                                                 dtype='|S50')])\n",
    "N = EPICnums.size\n",
    "print N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get GAIA data on K2 low mass stars with planets\n",
    "\n",
    "Cross-match K2 low mass stars with planets to GAIA DR2 and save parallaxes, photometry, and positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get GAIA data from Megan Bedell's Kepler-GAIA catalog\n",
    "hdu = fits.open('K2targets/k2_dr2_4arcsec.fits')[1]\n",
    "\n",
    "hasGAIA = np.zeros(N, dtype=bool)\n",
    "pars, epars = np.zeros(N), np.zeros(N)\n",
    "GBPmags, eGBPmags = np.zeros(N), np.zeros(N)\n",
    "GRPmags, eGRPmags = np.zeros(N), np.zeros(N)\n",
    "ras, decs = np.zeros(N), np.zeros(N)\n",
    "ls, bs = np.zeros(N), np.zeros(N)\n",
    "for i in range(N):\n",
    "    \n",
    "    g = hdu.data['epic_number'] == EPICnums[i]\n",
    "    if g.sum() == 0:   # no match\n",
    "        pars[i], epars[i] = np.repeat(np.nan, 2)\n",
    "        GBPmags[i], eGBPmags[i] = np.repeat(np.nan, 2)\n",
    "        GRPmags[i], eGRPmags[i] = np.repeat(np.nan, 2)\n",
    "        ras[i], decs[i] = np.repeat(np.nan, 2)\n",
    "        ls[i], bs[i] = np.repeat(np.nan, 2)\n",
    "        \n",
    "    elif g.sum() >= 1:  # at least one match (take the first entry if multiple matches)\n",
    "        index = 0\n",
    "        hasGAIA[i] = True\n",
    "        pars[i], epars[i] = hdu.data['parallax'][g][index], hdu.data['parallax_error'][g][index]\n",
    "\n",
    "        GBPmags[i] = hdu.data['phot_bp_mean_mag'][g][index]            \n",
    "        FBP = hdu.data['phot_bp_mean_flux'][g][index]\n",
    "        eFBP = hdu.data['phot_bp_mean_flux_error'][g][index]\n",
    "        eGBPmags[i] = -2.5*np.log10(FBP / (FBP+eFBP))\n",
    "        \n",
    "        GRPmags[i] = hdu.data['phot_rp_mean_mag'][g][index]            \n",
    "        FRP = hdu.data['phot_rp_mean_flux'][g][index]\n",
    "        eFRP = hdu.data['phot_rp_mean_flux_error'][g][index]\n",
    "        eGRPmags[i] = -2.5*np.log10(FRP / (FRP+eFRP))\n",
    "        \n",
    "        ras[i], decs[i] = hdu.data['ra'][g][index], hdu.data['dec'][g][index]\n",
    "        ls[i], bs[i] = hdu.data['l'][g][index], hdu.data['b'][g][index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute distance posteriors (from Bailor-Jones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get distance posteriors from Bailor-Jones R scripts\n",
    "cwd = os.getcwd()\n",
    "os.chdir('GaiaDistances/')\n",
    "prefix = 'EPICID'\n",
    "overwrite = False\n",
    "for i in range(N):\n",
    "       \n",
    "    cmd_prefix = 'Rscript get_dist_post.R %s'%prefix\n",
    "    cmd = '%s_%i %.6e %.6e %.6f %.6f'%(cmd_prefix, EPICnums[i], pars[i], epars[i], ls[i], bs[i])\n",
    "\n",
    "    # if posterior doesn't exist, compute it using the R script\n",
    "    fout = 'DistancePosteriors/%s_%i.csv'%(prefix, EPICnums[i])\n",
    "    if ((not os.path.exists(fout)) or overwrite) and (hasGAIA[i]):\n",
    "        os.system(cmd)\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save distance point estimates\n",
    "Nsamp = 1000\n",
    "dists, ehidists, elodists = np.zeros(N), np.zeros(N), np.zeros(N)\n",
    "mus, ehimus, elomus = np.zeros(N), np.zeros(N), np.zeros(N)\n",
    "for i in range(N):\n",
    "    \n",
    "    if hasGAIA[i]:\n",
    "        # get distance posterior\n",
    "        fname = 'GaiaDistances/DistancePosteriors/%s_%i.csv'%(prefix, EPICnums[i])\n",
    "        distarr, probarr = np.loadtxt(fname, delimiter=',', skiprows=1, usecols=(1,2)).T\n",
    "        samp_dist = np.random.choice(distarr, Nsamp, p=probarr/probarr.sum()) + np.random.randn(Nsamp)*1e-2\n",
    "\n",
    "        # save distance point estimates\n",
    "        v = np.percentile(samp_dist, (16,50,84))\n",
    "        dists[i], ehidists[i], elodists[i] = v[1], v[2]-v[1], v[1]-v[0]\n",
    "    \n",
    "        # sample and save distance modulus\n",
    "        samp_mu = 5*np.log10(samp_dist) - 5\n",
    "        v = np.percentile(samp_mu, (16,50,84))\n",
    "        mus[i], ehimus[i], elomus[i] = v[1], v[2]-v[1], v[1]-v[0]\n",
    "        \n",
    "    else:\n",
    "        dists[i], ehidists[i], elodists[i] = np.repeat(np.nan, 3)\n",
    "        mus[i], ehimus[i], elomus[i] = np.repeat(np.nan, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimate extinction using mwdust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_AK_mwdust(ls, bs, dist, edist, eAK_frac=.3, RV=3.1):\n",
    "    '''Using the EB-V map from 2014MNRAS.443.2907S and the extinction vector\n",
    "    RK = 0.31 from Schlafly and Finkbeiner 2011 (ApJ 737, 103). \n",
    "    Where does RV=3.1 come from? See the MIST BC tables where RV is fixed to 3.1'''\n",
    "    dustmapK = mwdust.Combined15(filter='2MASS Ks')\n",
    "    dustmapV = mwdust.Combined15(filter=None)  # returns E(B-V) rather than A_lambda\n",
    "    dist_kpc, edist_kpc = np.ascontiguousarray(dist)*1e-3, \\\n",
    "                          np.ascontiguousarray(edist)*1e-3\n",
    "    ls, bs = np.ascontiguousarray(ls), np.ascontiguousarray(bs)\n",
    "    AK, eAK = np.zeros(ls.size), np.zeros(ls.size)\n",
    "    AV = np.zeros(ls.size)\n",
    "    for i in range(ls.size):\n",
    "        v = dustmapK(ls[i], bs[i],\n",
    "                     np.array([dist_kpc[i], dist_kpc[i]+edist_kpc[i]]))\n",
    "        AK[i], eAK[i] = v[0], np.sqrt(abs(np.diff(v))**2 + (eAK_frac*v[0])**2)\n",
    "        v = dustmapV(ls[i], bs[i],\n",
    "                     np.array([dist_kpc[i], dist_kpc[i]+edist_kpc[i]]))\n",
    "        AV[i] = v[0]*RV\n",
    "    return AK, eAK, AV\n",
    "\n",
    "\n",
    "def MAD(arr):\n",
    "    return np.median(abs(arr - np.median(arr)))\n",
    "    \n",
    "\n",
    "AKs, eAKs = np.zeros(N), np.zeros(N)\n",
    "for i in range(N):\n",
    "    \n",
    "    if hasGAIA[i]:\n",
    "\n",
    "        # get distance posterior\n",
    "        fname = 'GaiaDistances/DistancePosteriors/EPICID_%i.csv'%EPICnums[i]\n",
    "        distarr, probarr = np.loadtxt(fname, delimiter=',', skiprows=1, usecols=(1,2)).T\n",
    "        samp_dist = np.random.choice(distarr, Nsamp, p=probarr/probarr.sum()) + np.random.randn(Nsamp)*1e-2\n",
    "        \n",
    "        # compute K-band extinction\n",
    "        AKs[i], eAKs[i],_ = _compute_AK_mwdust(ls[i], bs[i], dists[i], MAD(samp_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute new stellar parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sample_Rs_from_MK_Mdwarfs(samp_MK):\n",
    "    '''Use relation from Mann+2015 (table 1) for M dwarfs'''\n",
    "    if (np.median(samp_MK) >= 4.6) & (np.median(samp_MK) <= 9.8):\n",
    "        a, b, c, Rs_sigma_frac = 1.9515, -.3520, .01680, .0289\n",
    "        p = np.poly1d((c,b,a))\n",
    "        samp_MK_tmp = np.copy(samp_MK)\n",
    "        #samp_MK_tmp[(samp_MK<=4.6) | (samp_MK>=9.8)] = np.nan\n",
    "        samp_Rs = p(samp_MK_tmp)\n",
    "        samp_Rs += np.random.normal(0, samp_Rs*Rs_sigma_frac, samp_MK.size)\n",
    "    else:\n",
    "        samp_Rs = np.zeros_like(samp_MK) + np.nan\n",
    "    return samp_Rs\n",
    "\n",
    "\n",
    "def _sample_Teff_from_colors(samp_GBPmag, samp_GRPmag, samp_Jmag, samp_Hmag,\n",
    "                             Teff_scatter=49):\n",
    "    '''Use the relation from Mann+2015 (table 2)'''\n",
    "    a, b, c, d, e, f, g = 3.172, -2.475, 1.082, -.2231, .01738, .08776, -.04355\n",
    "    pG = np.poly1d((e,d,c,b,a))\n",
    "    p2 = np.poly1d((g,f,0))\n",
    "    samp_Teff = 35e2 * (pG(samp_GBPmag-samp_GRPmag) + p2(samp_Jmag-samp_Hmag)) \\\n",
    "                + np.random.normal(0, Teff_scatter, samp_Jmag.size)\n",
    "    return samp_Teff\n",
    "\n",
    "\n",
    "def _sample_Ms_from_MK(samp_MK):\n",
    "    '''Use relation from Benedict+2016'''\n",
    "    if (np.median(samp_MK) >= 4.6) & (np.median(samp_MK) <= 9.8):\n",
    "        c0 = np.random.normal(.2311, 4e-4, samp_MK.size)\n",
    "        c1 = np.random.normal(-.1352, 7e-4, samp_MK.size)\n",
    "        c2 = np.random.normal(.04, 5e-4, samp_MK.size)\n",
    "        c3 = np.random.normal(.0038, 2e-4, samp_MK.size)\n",
    "        c4 = np.random.normal(-.0032, 1e-4, samp_MK.size)\n",
    "        samp_MK_tmp = np.copy(samp_MK)\n",
    "        #samp_MK_tmp[(samp_MK<=4.6) | (samp_MK>10)] = np.nan\n",
    "        #samp_MK_tmp[samp_MK>=10] = np.nan\n",
    "        dMK = samp_MK_tmp - 7.5\n",
    "        samp_Ms = c0 + c1*dMK + c2*dMK**2 + c3*dMK**3 + c4*dMK**4\n",
    "    else:\n",
    "        samp_Ms = np.zeros_like(samp_MK) + np.nan\n",
    "    return samp_Ms\n",
    "\n",
    "\n",
    "def _compute_logg(Ms, Rs):\n",
    "    G = 6.67e-11\n",
    "    return np.log10(G*rvs.Msun2kg(Ms)*1e2 / rvs.Rsun2m(Rs)**2)\n",
    "\n",
    "\n",
    "def _compute_percentiles(samples):\n",
    "    v = np.percentile(samples, (16,50,84))\n",
    "    return v[1], v[2]-v[1], v[1]-v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryancloutier/anaconda2/lib/python2.7/site-packages/numpy/lib/function_base.py:4291: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    }
   ],
   "source": [
    "nanarr = np.repeat(np.nan, N)\n",
    "isMdwarf = np.zeros(N, dtype=bool)\n",
    "MKs, ehiMKs, eloMKs = np.copy(nanarr), np.copy(nanarr), np.copy(nanarr)\n",
    "Rss2, ehiRss2, eloRss2 = np.copy(nanarr), np.copy(nanarr), np.copy(nanarr)\n",
    "Teffs2, ehiTeffs2, eloTeffs2 = np.copy(nanarr), np.copy(nanarr), np.copy(nanarr)\n",
    "Mss2, ehiMss2, eloMss2 = np.copy(nanarr), np.copy(nanarr), np.copy(nanarr)\n",
    "loggs2, ehiloggs2, elologgs2 = np.copy(nanarr), np.copy(nanarr), np.copy(nanarr)\n",
    "for i in range(N):\n",
    "    \n",
    "    if hasGAIA[i]:\n",
    "        # sample input parameters\n",
    "        samp_Jmag = np.random.randn(Nsamp)*eJmag[i] + Jmag[i]\n",
    "        samp_Hmag = np.random.randn(Nsamp)*eHmag[i] + Hmag[i]\n",
    "        samp_Kmag = np.random.randn(Nsamp)*eKmag[i] + Kmag[i]\n",
    "        samp_GBPmag = np.random.randn(Nsamp)*eGBPmags[i] + GBPmags[i]\n",
    "        samp_GRPmag = np.random.randn(Nsamp)*eGRPmags[i] + GRPmags[i]\n",
    "        samp_AK = np.random.randn(Nsamp)*eAKs[i] + AKs[i]\n",
    "        _,_,samp_mu = estimate_PDF.get_samples_from_percentiles(mus[i], ehimus[i], elomus[i], Nsamp=Nsamp)\n",
    "\n",
    "        # compute updated stellar parameters\n",
    "        samp_MK = samp_Kmag - samp_mu - samp_AK\n",
    "        MKs[i], ehiMKs[i], eloMKs[i] = _compute_percentiles(samp_MK)\n",
    "        isMdwarf[i] = (MKs[i] > 4.6) & (MKs[i] < 9.8)\n",
    "        samp_Rs = _sample_Rs_from_MK_Mdwarfs(samp_MK)\n",
    "        Rss2[i], ehiRss2[i], eloRss2[i] = _compute_percentiles(samp_Rs)\n",
    "        Teffs2[i], ehiTeffs2, eloTeffs2[i] = _compute_percentiles(_sample_Teff_from_colors(samp_GBPmag, samp_GRPmag,\n",
    "                                                                                           samp_Jmag, samp_Hmag))\n",
    "        samp_Ms = _sample_Ms_from_MK(samp_MK)\n",
    "        Mss2[i], ehiMss2[i], eloMss2[i] = _compute_percentiles(samp_Ms)\n",
    "        loggs2[i], ehiloggs2[i], elologgs2[i] = _compute_percentiles(_compute_logg(samp_Ms, samp_Rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
